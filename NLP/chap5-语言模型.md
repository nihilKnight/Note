# 语言模型

- [基本概念](#基本概念)
- [参数估计](#参数估计)
- [数据平滑](#数据平滑)
- [语言模型的自适应](#语言模型的自适应)
- [语言模型应用举例](#语言模型应用举例)
- [神经网络语言模型](#神经网络语言模型)

## 基本概念

1. 基于大规模语料库和统计方法，可以：
    - 发现语言使用的普遍规律；
    - 进行机器学习，自动获取语言知识；
    - 对未知现象进行推测。

2. 语言模型：以一段文字为单位统计相对频率，再根据句子构成单位的概率计算联合概率。
    > 计算语句$s=w_1w_2\cdots w_n$的先验概率：
    > $$
    > \begin{aligned}
    > p(s)&=p(w_1)\times p(w_2|w_1)\times p(w_3|w_2w_1)\times\cdots\times p(w_m|w_1\cdots w_{m-1})\\
    > &=\prod_{i=1}^m p(w_i|w_1\cdots w_{i-1})\quad(i=1,p(w_1|w_0)=p(w_1))
    > \end{aligned}
    > $$
    > 其中：
    > - $w_i$被称为**统计基元**或“**词**”，可以是字、词、短语或词类等。
    > - $w_i$的概率由$w_1,\cdots,w_{i-1}$决定，由特定的一组$w_1,\cdots,w_{i-1}$构成的一个序列，称为$w_i$的**历史**。

3. 问题：**不同的“历史”**随统计基元数量的**指数级增长**。
    > 如果有$L$个不同的基元，则对于第$i(i>1)$个统计基元，其具有$i-1$个历史基元，则有$L^{i-1}$种不同的历史。则模型中共有$L^m$个自由参数。
    > $$
    > p(w_m|w_1\cdots w_{m-1})
    > $$

4. 解决方法：划分等价类。
    > **$n$元文法（$n$-gram）**：将两个历史映射到同一个等价类，当且仅当这两个历史中最近的$n-1$个基元相同，即：
    > $$
    > S(w_1,w_2,\cdots,w_i)=S(v_1,v_2,\cdots,v_k)\iff H_1:(w_{i-n+1},\cdots,w_i)=H_2:(v_{k-n+1},\cdots,v_k)
    > $$
    > - 当$n=1$时，则第$i$位的基元$w_i$独立于历史。一元文法也称uni-gram或monogram；
    > - 当$n=2/3$时，分别称$2$-gram（bi-gram）/ $3$-gram（tri-gram) 为1/2阶**马尔科夫链**。
    > 
    > 首位标志符：为使条件概率在$i=1$时有意义，为保证且句子内所有字符串的概率和为1，可以在句子首尾添加标志符：$\langle BOS\rangle,\langle EOS\rangle$。不失一般性地，对$n>2$的$n$-gram，$p(s)$可以分解为：
    > $$
    > p(s)=\prod_{i=1}^{m+1}p(w_i|w^{i-1}_{i-n+1})
    > $$
    > 其中，$w_i^j$表示词序列$w_i\cdots w_j$，$w_{j-n+1}$从$w_0$开始，

5. 应用：（1）音字转换问题；（2）汉语分词问题。
    - 音字转换问题：
        > $\overset{\frown}{C}String=\argmax\limits_{CString} p(CString)$.
    - 汉语分词问题：
        > $\overset{\frown}{S}eg=\argmax\limits_{Seg} p(Seg)$.

## 参数估计

1. 重要概念：（1）**训练语料**：用于建立模型，确定模型参数的已知预料；（2）**最大似然估计**：用相对频率计算概率的方法。
    > 对于$n$-gram，参数$p(w_1|w_{i-n+1}^{i-1})$可由最大似然估计求得：
    > $$
    > p(w_i|w_{i-n+1}^{i-1})=f(w_i|w_{i-n+1}^{i-1})=\dfrac{c(w_{i-n+1}^i)}{\sum_{w_i}c(w_{i-n+1}^i)}
    > $$

2. **数据平滑**：数据匮乏(Sparse Data）或稀疏引起的**零概率问题**。

## 数据平滑

1. 基本思想：调整最大似然估计的概率值，使零概率增值、非零概率下调。从而消除零概率，改进模型的整体正确率。
    - 基本目标：测试样本的语言模型困惑度越小越好。
    - 基本约束：$\sum_{w_i}p(w_i|w_1,w_2,\cdots,w_{i-1})=1$。

2. 

## 语言模型的自适应

## 语言模型应用举例

## 神经网络语言模型